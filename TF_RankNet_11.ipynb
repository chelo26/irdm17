{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import math\n",
    "# import pandas\n",
    "from optparse import OptionParser\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import ensemble\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from multiprocessing import Pool\n",
    "from itertools import chain\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to extrac the documents, query and rank information\n",
    "def extractFeatures(split):\n",
    "    features = []\n",
    "    for i in range(2, 138):\n",
    "        features.append(float(split[i].split(':')[1]))\n",
    "    # Convert to tuples:\n",
    "    return features\n",
    "\n",
    "def extractQueryData(split):\n",
    "    # Add tuples:\n",
    "    queryFeatures = split[1].split(':')[1]\n",
    "    return queryFeatures\n",
    "\n",
    "def readDataset(path):\n",
    "    print('Reading training data from file...')\n",
    "    with open(path, 'r') as file:\n",
    "        #k=0\n",
    "        features_list=[]\n",
    "        rank_list=[]\n",
    "        query_list=[]\n",
    "        doc_id= []\n",
    "        i= 0\n",
    "        for line in file:\n",
    "            split = line.split()\n",
    "            features_list.append(extractFeatures(split))\n",
    "            rank_list.append(int(split[0]))\n",
    "            query_list.append(extractQueryData(split))\n",
    "            #k+=1\n",
    "            #if k==100:\n",
    "            #    break\n",
    "    #print('Number of query ID %d' %(len(features_list)))\n",
    "    return features_list, rank_list, query_list\n",
    "\n",
    "\n",
    "# Normalisation:\n",
    "def normalize_features(features):\n",
    "    features=np.array(features)\n",
    "\n",
    "    # Substracting the mean:\n",
    "    mean_features = np.mean(features, axis=0)\n",
    "    features = features - mean_features\n",
    "\n",
    "    # Dividing by the std:\n",
    "    std_features = np.std(features, axis=0)\n",
    "    features = features / std_features\n",
    "    #print \"features normalized\"\n",
    "    return features\n",
    "\n",
    "\n",
    "# We put everything in a dictionary (key,value)= (query_id,[features,rank])\n",
    "def make_dictionary(features,ranks,queries):\n",
    "    dictio_quid=defaultdict(list)\n",
    "    doc_id_1 = 0\n",
    "    for feature_vec, rank, query, in zip(features, ranks, queries):\n",
    "        dictio_quid[query].append((feature_vec, rank, doc_id_1))\n",
    "        doc_id_1+= 1\n",
    "    return dictio_quid\n",
    "\n",
    "# Given a query ID, we separate on: [Xi,Xj,P_true] where P_true is either 0,0.5 or 1\n",
    "def get_pairs_features(dictio_quid_featsRank):\n",
    "    data = []\n",
    "    qid_lst = []\n",
    "    #k = 0\n",
    "    for key in dictio_quid_featsRank.keys():\n",
    "        # Temporary list of features,rank\n",
    "        temp_list = dictio_quid_featsRank[key]\n",
    "\n",
    "        for i in range(0, len(temp_list)):\n",
    "            X1 = temp_list[i][0]\n",
    "            rank1 = temp_list[i][1]\n",
    "            doc1_id = temp_list[i][2]\n",
    "            \n",
    "            for j in range(i + 1, len(temp_list)):\n",
    "                X2 = temp_list[j][0]\n",
    "                rank2 = temp_list[j][1]\n",
    "                doc2_id = temp_list[i][2]\n",
    "                \n",
    "                doc_id = (doc1_id, doc2_id)\n",
    "\n",
    "                # Only look at queries with different id:\n",
    "                if (rank1 == rank2):\n",
    "                    data.append((X1, X2, 0.5, key, doc_id))\n",
    "                if (rank1 > rank2):\n",
    "                    data.append((X1, X2, int(1), key, doc_id))\n",
    "                else:\n",
    "                    data.append((X1, X2, int(0), key, doc_id))\n",
    "    return data\n",
    "\n",
    "# Putting in the good format for tensorflow:\n",
    "def separate(data):\n",
    "    Xi = []\n",
    "    Xj = []\n",
    "    P_target = []\n",
    "    quid = []\n",
    "    doc_id = []\n",
    "    for instance in data:\n",
    "        Xi.append(instance[0])\n",
    "        Xj.append(instance[1])\n",
    "        P_target.append(instance[2])\n",
    "        quid.append(instance[3])\n",
    "        doc_id.append(instance[4])\n",
    "    return (np.array(Xi), np.array(Xj), np.array(P_target), np.array(quid), np.array(doc_id))\n",
    "\n",
    "# Sampling:\n",
    "def sampling_data(training_data, batch_size):\n",
    "    N = len(training_data)\n",
    "    indices = np.random.choice(N, batch_size)\n",
    "    #print (\"%d indices Selected\" ) % batch_size\n",
    "    return [training_data[i] for i in indices]\n",
    "\n",
    "# TensorFlow save model \n",
    "def save_model(sess):\n",
    "    print('Saving model...')\n",
    "    if not os.path.exists('./model/'):\n",
    "        os.mkdir('./model/')\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './model/model.checkpoint')\n",
    "    print('Model saved')\n",
    "    \n",
    "def load_model():\n",
    "    print('Loading model...')\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "    print('Model loaded')\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read training data\n",
    "features, ranks, queries = readDataset('LEMUR/MSLR-WEB10K/Fold1/vali.txt')\n",
    "features = normalize_features(features)\n",
    "dictio_quid = make_dictionary(features, ranks, queries)\n",
    "training_data = get_pairs_features(dictio_quid)\n",
    "sampled_data = sampling_data(training_data, 10000)\n",
    "Xi, Xj, P_target, quid, doc_id  = separate(sampled_data)\n",
    "P_target_r= np.reshape(P_target, (-1, 1))\n",
    "quid_r= np.reshape(quid, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Validation set\n",
    "val_features, val_ranks, val_queries = readDataset('LEMUR/MSLR-WEB10K/Fold1/test.txt')\n",
    "val_features= normalize_features(val_features)\n",
    "val_dictio_quid = make_dictionary(val_features, val_ranks, val_queries)\n",
    "val_training_data = get_pairs_features(val_dictio_quid)\n",
    "val_sampled_data = sampling_data(val_training_data, 10000)\n",
    "val_Xi, val_Xj, val_P_target = separate(val_sampled_data)\n",
    "val_P_target_r= np.reshape(val_P_target, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reorder_dictio(dictio_eval):\n",
    "    for key in dictio_eval.keys():\n",
    "        #dictio_eval[key]=sorted(dictio_eval[key], reverse=True,key=lambda tup: (tup[1], tup[0]))\n",
    "        dictio_eval[key] = sorted(dictio_eval[key], reverse=True, key=lambda tup: tup[1])\n",
    "    return dictio_eval\n",
    "\n",
    "def dcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "\n",
    "    # highest rank is 1 so +2 instead of +1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    best = dcg_score(y_true, y_true, k, gains)\n",
    "    actual = dcg_score(y_true, y_score, k, gains)\n",
    "    return actual / best\n",
    "\n",
    "def separate(relevance_tuple):\n",
    "    y_true=[]\n",
    "    y_pred = []\n",
    "    for tup in relevance_tuple:\n",
    "        y_pred.append(tup[0])\n",
    "        y_true.append(tup[1])\n",
    "    return y_true,y_pred\n",
    "\n",
    "def ndcg(dictio_eval):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    b= reorder_dictio(dictio_eval)\n",
    "    new_b=[]\n",
    "    for qid in b.keys():\n",
    "        r_true=[]\n",
    "        r_pred=[]\n",
    "        for i,j in zip(pd.DataFrame(b[qid])[0], pd.DataFrame(b[qid])[1]):\n",
    "            r_pred.append(i)\n",
    "            r_true.append(j)\n",
    "        score=ndcg_score(r_true,r_pred)    \n",
    "        #new_b[qid]= [r_true, r_pred]\n",
    "        new_b.append(score)\n",
    "    return new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to calculate ERR:\n",
    "GAMMA=0.450\n",
    "\n",
    "## Different:\n",
    "def get_proba(list_tuples,bins):\n",
    "    list_proba=[]\n",
    "    list_score = [i[0] for i in list_tuples]\n",
    "#    print list_score\n",
    "    list_true = range(len(list_tuples))\n",
    "#   print list_true\n",
    "    pred_relevance = list_score #assign_to_bin(list_score,bins)\n",
    "#    print pred_relevance\n",
    "    list_tuples=zip(pred_relevance,list_true)\n",
    "    for r_pred,r_true in list_tuples:\n",
    "        proba = ((np.power(2,r_pred))-1)/ np.power(2,4)#np.max(r_pred))\n",
    "        list_proba.append(proba)\n",
    "    return list_proba\n",
    "\n",
    "def get_ERR(list_proba,n=10,gamma=0.5):\n",
    "    r=2\n",
    "    err = list_proba[0]\n",
    "    last_proba=1\n",
    "    for i in range(1,len(list_proba)):\n",
    "        actual_proba=list_proba[i]\n",
    "        previous_proba=(1-list_proba[i-1])*last_proba\n",
    "        #print proba\n",
    "        stop_proba=actual_proba*previous_proba\n",
    "        err+=stop_proba/r\n",
    "        last_proba=previous_proba\n",
    "        r+=1\n",
    "    return err\n",
    "\n",
    "def ERR(dictio_eval,n=10,gamma=GAMMA):\n",
    "    list_ERR=[]\n",
    "    # Get the bins:\n",
    "    bins=get_bins(dictio_eval)\n",
    "    for key in dictio_eval.keys():\n",
    "        list_tuples=dictio_eval[key]\n",
    "        list_proba=get_proba(list_tuples,bins)\n",
    "        err_result=get_ERR(list_proba,n,gamma)\n",
    "        list_ERR.append(err_result)\n",
    "    return list_ERR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dictio_val, mean_Xval, std_Xval):\n",
    "    dictio_evaluation = defaultdict(list)\n",
    "\n",
    "    for key in dictio_val.keys():\n",
    "        temp_list = dictio_val[key]\n",
    "        for features_vec, relevance in temp_list:\n",
    "            # Features:\n",
    "            features_norm = (np.array(features_vec) - mean_Xval) / std_Xval\n",
    "            features_norm = features_norm.reshape(1,-1)\n",
    "            #features_norm = features_norm.reshape(-1,1)\n",
    "\n",
    "            # Prediction:\n",
    "            prediction = model.predict(features_norm)\n",
    "\n",
    "            # Dictionary:\n",
    "            dictio_evaluation[key].append((prediction[0], relevance))\n",
    "\n",
    "            # print features_vec,relevance\n",
    "\n",
    "    return dictio_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TF_RankNet():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.self = self\n",
    "        \n",
    "    def initilise_model(self):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.x_i = tf.placeholder(\"float\", [None, 136])\n",
    "        self.x_j = tf.placeholder(\"float\", [None, 136])\n",
    "        self.y_gold = tf.placeholder(\"float\", [None, 1])\n",
    "        self.q_id = tf.placeholder(\"string\", [None, 1])\n",
    "\n",
    "        d_in = 136\n",
    "        d_hidden1 = 500\n",
    "        d_out = 1\n",
    "\n",
    "        self.W1 = tf.Variable(tf.random_normal([d_in, d_hidden1], mean= 0, stddev= 0.01))\n",
    "        self.b1 = tf.Variable(tf.random_normal([d_hidden1], mean= 1, stddev= 0.01))\n",
    "        self.W2 = tf.Variable(tf.random_normal([d_hidden1, d_out], mean= 0, stddev= 0.01))\n",
    "        self.b2 = tf.Variable(tf.random_normal([d_out], mean= 1, stddev= 0.01))\n",
    "\n",
    "        self.a1_i = tf.matmul(self.x_i, self.W1)+ self.b1\n",
    "        self.z1_i = tf.nn.tanh(self.a1_i)\n",
    "        self.a2_i = tf.matmul(self.z1_i, self.W2)+ self.b2\n",
    "        self.o_i = tf.nn.tanh(self.a2_i)\n",
    "\n",
    "        self.a1_j = tf.matmul(self.x_j, self.W1)+ self.b1\n",
    "        self.z1_j = tf.nn.tanh(self.a1_j)\n",
    "        self.a2_j = tf.matmul(self.z1_j, self.W2)+ self.b2\n",
    "        self.o_j = tf.nn.tanh(self.a2_j)\n",
    "\n",
    "        self.o_ij = tf.multiply(tf.subtract(self.o_i, self.o_j), 2)\n",
    "        self.P_ij = tf.sigmoid(self.o_ij)\n",
    "\n",
    "        self.loss = tf.reduce_mean(tf.losses.mean_squared_error(self.y_gold, self.P_ij))\n",
    "\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = 0.0001\n",
    "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "\n",
    "        self.optimiser = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        self.prediction = (tf.round((tf.clip_by_value(self.P_ij, 0.01, 0.99) * 3)+ 0.5) -1)/ 2 \n",
    "\n",
    "        self.mistakes = tf.not_equal(self.y_gold, self.prediction)\n",
    "        self.accuracy = 1- tf.reduce_mean(tf.cast(self.mistakes, tf.float32))\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def train_1(self, x_i_train, x_j_train, y_train, quid, epoch):\n",
    "        print('Train with all data, unbatched')\n",
    "        \n",
    "        self.train_dict= {self.x_i: x_i_train[:10],\n",
    "                          self.x_j: x_j_train[:10],\n",
    "                          self.y_gold: y_train[:10], \n",
    "                          self.q_id: quid[:10]} \n",
    "        print('Initial training acc %s' % (sess.run(self.accuracy, feed_dict= self.train_dict)))\n",
    "        for i in range(epoch):\n",
    "            sess.run(self.optimiser, feed_dict= self.train_dict)\n",
    "        print('Final training acc %s' % (sess.run(self.accuracy, feed_dict= self.train_dict)))\n",
    "        \n",
    "    def train_full(self, x_i_train, x_j_train, y_train, epoch, batch_sz, x_valid= None, y_valid= None):\n",
    "\n",
    "        self.iter_= int(x_i_train.shape[0]/ batch_sz)\n",
    "        \n",
    "        self.train_dict= {self.x_i: x_i_train,\n",
    "                          self.x_j: x_j_train,\n",
    "                          self.y_gold: y_train} \n",
    "    \n",
    "        print('Training: Iters: %s. Epoch:  %s' % (self.iter_, epoch))\n",
    "        print('Initial training acc %s' % (sess.run(self.accuracy, feed_dict= self.train_dict)))\n",
    "        \n",
    "        for e in range(epoch):\n",
    "            e_loss= 0\n",
    "                \n",
    "            for i in range(self.iter_):\n",
    "                iter_dict= {self.x_i: x_i_train[(i* batch_sz):((i+ 1)* batch_sz)],\n",
    "                            self.x_j: x_j_train[(i* batch_sz):((i+ 1)* batch_sz)],\n",
    "                            self.y_gold: y_train[(i* batch_sz):((i+ 1)* batch_sz)]}\n",
    "                \n",
    "                sess.run(self.optimiser, feed_dict= iter_dict)\n",
    "                e_loss+= sess.run(self.loss, feed_dict= iter_dict)\n",
    "                \n",
    "                #if i %300 == 0:\n",
    "                #    print('Epoch %s, iter %s, loss %s' % (e, i, sess.run(self.loss, feed_dict= iter_dict)))\n",
    "                \n",
    "            print('Epoch %s, loss %s' % (e, sess.run(self.loss, feed_dict= iter_dict)))\n",
    "        print('Training accuracy %s' % (sess.run(self.accuracy, feed_dict= self.train_dict)))\n",
    "        \n",
    "    def predict(self, x_i_train, x_j_train, quid):\n",
    "        valid_dict= {self.x_i: x_i_train,\n",
    "                     self.x_j: x_j_train,\n",
    "                     self.q_id: quid}\n",
    "        predict_1 = (sess.run(self.prediction, feed_dict= valid_dict))\n",
    "        predict = (sess.run(self.P_ij, feed_dict= valid_dict))\n",
    "        q_id_out = (sess.run(self.q_id, feed_dict= valid_dict))\n",
    "        \n",
    "        return predict_1, predict, q_id_out\n",
    "        \n",
    "    def test_pointwise(self, x_i_train, x_j_train, y_train):\n",
    "        self.valid_dict= {self.x_i: x_i_train,\n",
    "                          self.x_j: x_j_train,\n",
    "                          self.y_gold: y_train} \n",
    "        val_accuracy = (sess.run(self.accuracy, feed_dict= self.valid_dict))\n",
    "        print('Test accuracy: %s' % (val_accuracy))\n",
    "        \n",
    "    def save_model(self, sess, dir_name):\n",
    "        print('Saving model...')\n",
    "        if not os.path.exists('./'+ dir_name+ '/'):\n",
    "            os.mkdir('./'+ dir_name+ '/')\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './'+ dir_name+ '/model.checkpoint')\n",
    "        print('Model saved')\n",
    "\n",
    "    def load_model(self, sess, dir_name):\n",
    "        print('Loading model...')\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, './'+ dir_name+ '/model.checkpoint')\n",
    "        print('Model loaded')\n",
    "        return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('---Start---')\n",
    "\n",
    "model1= TF_RankNet()\n",
    "model1.initilise_model()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    print('1. Initialise')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #model1.load_model(sess, 'TF_RankNet')\n",
    "    \n",
    "    model1.test_pointwise(tes_features, tes_ranks_enc)\n",
    "    \n",
    "    #pred_dictio_eval = evaluate(model1, tes_queries, mean_Xval, std_Xval)\n",
    "    #nDGC_eval_lst = ndcg(pred_dictio_eval)\n",
    "    #ERR_eval_lst = ERR(pred_dictio_eval)\n",
    "    print('Pre-train nDGC tes: %s, ERR: %s' % (np.nanmean(nDGC_eval_lst), np.nanmean(ERR_eval_lst)))\n",
    "    \n",
    "    print('2. Train')\n",
    "    model1.train_full(features, ranks_enc, 10, 30)\n",
    "    \n",
    "    print('3. Test')\n",
    "    model1.test_pointwise(tes_features, tes_ranks_enc)\n",
    "    \n",
    "    #pred_dictio_eval = evaluate(model1, tes_queries, mean_Xval, std_Xval)\n",
    "    #nDGC_eval_lst = ndcg(pred_dictio_eval)\n",
    "    #ERR_eval_lst = ERR(pred_dictio_eval)\n",
    "    \n",
    "    print('Post-train nDGC tes: %s, ERR: %s' % (np.nanmean(nDGC_eval_lst), np.nanmean(ERR_eval_lst)))\n",
    "    model1.save_model(sess, 'TF_RankNet')\n",
    "    \n",
    "print('---End---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
