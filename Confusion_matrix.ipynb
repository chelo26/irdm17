{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import math\n",
    "# import pandas\n",
    "from optparse import OptionParser\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import ensemble\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from multiprocessing import Pool\n",
    "from itertools import chain\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from __future__ import division\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to extrac the documents, query and rank information\n",
    "def extractFeatures(split):\n",
    "    features = []\n",
    "    for i in range(2, 138):\n",
    "        features.append(float(split[i].split(':')[1]))\n",
    "    # Convert to tuples:\n",
    "    return features\n",
    "\n",
    "def extractQueryData(split):\n",
    "    # Add tuples:\n",
    "    queryFeatures = split[1].split(':')[1]\n",
    "    return queryFeatures\n",
    "\n",
    "def readDataset(path):\n",
    "    dictio_quid= defaultdict(list)\n",
    "    features_list=[]\n",
    "    rank_list=[]\n",
    "    print('Reading training data from file...')\n",
    "    k=0\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Getting features:\n",
    "            split = line.split()\n",
    "            features=extractFeatures(split)\n",
    "            features_list.append(features)\n",
    "\n",
    "            # Getting the query:\n",
    "            query = int(extractQueryData(split))\n",
    "            #print \"query: \"+str(query)\n",
    "            # Getting rank:\n",
    "            rank = int(split[0])\n",
    "            rank_list.append(rank)\n",
    "\n",
    "            # Feeding dictionary:\n",
    "            dictio_quid[query].append((features, rank))\n",
    "            k+=1\n",
    "            #if k==10:\n",
    "            #   break\n",
    "    print('Number of query ID %d' %(len(features_list)))\n",
    "    return np.array(features_list), np.array(rank_list), dictio_quid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, tes_ranks, __= readDataset('MSLR-WEB10K/Fold1/test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the list of scores:\n",
    "import os\n",
    "list_scores=[]\n",
    "for file in os.listdir(\"best_models/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        list_scores.append(os.path.join(\"best_models/\", file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_models/test_LM_rank_score_LambdaMART1.txt',\n",
       " 'best_models/test_RB_rank_score_RB_model_r100_tc10.txt',\n",
       " 'best_models/test_RN_rank_score_RN_model_e20_l2_n1_lr5e-05.txt']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_names=[\"LambdaMart\",\"RankBoost\",\"RankNet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def txt_to_dictio_eval(file_name):\n",
    "    \n",
    "    model_output_array = np.loadtxt(file_name)\n",
    "    model_output_arr_rel = np.concatenate((model_output_array, np.reshape(tes_ranks, (-1, 1))), axis=1)\n",
    "    \n",
    "    \n",
    "    model_output_dict = defaultdict(list)\n",
    "    model_output_dict_or = defaultdict(list)\n",
    "\n",
    "    for i in model_output_arr_rel:\n",
    "        model_output_dict[i[0]].append((i[3], i[2]))\n",
    "\n",
    "    for i in model_output_dict.keys():\n",
    "        model_output_dict[i].sort(reverse=True)\n",
    "\n",
    "    for i in model_output_dict.keys():\n",
    "        model_output_dict_or[i] = [(x[1] ,x[0]) for x in model_output_dict[i]]\n",
    "        \n",
    "    return model_output_dict_or\n",
    "\n",
    "def get_bins(dictio_eval):\n",
    "    #Get the bins:\n",
    "    all_tuples=[]\n",
    "    for key in dictio_eval.keys():\n",
    "        all_tuples.append(dictio_eval[key])\n",
    "    all_tuples=list(chain.from_iterable(all_tuples))\n",
    "    all_scores=[i[0] for i in all_tuples]\n",
    "    all_true=[i[1] for i in all_tuples]\n",
    "    number_bins=4#len(set(all_true))\n",
    "    bins = np.histogram(all_scores, bins=number_bins, range=None, normed=False, weights=None)[1]\n",
    "    return bins, all_true, all_scores\n",
    "\n",
    "def assign_to_bin(list_score,bins):\n",
    "    # Get bins\n",
    "    #bins = np.histogram(list_score, bins=number_bins, range=None, normed=False, weights=None)[1]\n",
    "    inds = np.digitize(list_score, bins,right=True)\n",
    "    return inds\n",
    "\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    \n",
    "    print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "for i in list_scores[2:3]:\n",
    "    plot_confusion_matrix(sklearn.metrics.confusion_matrix(all_true, predicted_scores), [0,1,2,3,4])\n",
    "    plt.savefig(str(i[12:])+'.pdf')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
