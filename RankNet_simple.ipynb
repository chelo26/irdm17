{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "% pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RANK NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### -------------> Import data:\n",
    "\n",
    "def readDataset(path):\n",
    "    '''\n",
    "    Dataset - LETOR 4.0\n",
    "    Dataset format: svmlight / libsvm format\n",
    "    <label> <feature-id>:<feature-value>... #docid = <feature-value> inc = <feature-value> prob = <feature-value>\n",
    "    We have a total of 46 features\n",
    "    '''\n",
    "\n",
    "    X_train = [] #<feature-value>[46]\n",
    "    y_train = [] #<label>\n",
    "    Query = []   #<query-id><document-id><inc><prob>\n",
    "\n",
    "    print('Reading training data from file...')\n",
    "\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            split = line.split()\n",
    "            y_train.append(int(split[0]))\n",
    "            X_train.append(extractFeatures(split))\n",
    "            Query.append(extractQueryData(split))\n",
    "    print('Read %d lines from file...' %(len(X_train)))\n",
    "    return (X_train, y_train, Query)\n",
    "\n",
    "def extractFeatures(split):\n",
    "    '''\n",
    "    Extract the query to document features used\n",
    "    as input to the neural network\n",
    "    '''\n",
    "    features = []\n",
    "    for i in xrange(2, 138):\n",
    "        features.append(float(split[i].split(':')[1]))\n",
    "    return features\n",
    "\n",
    "def extractQueryData(split):\n",
    "    '''\n",
    "    Extract the query features from a dataset line\n",
    "    Format:\n",
    "    <query-id><document-id><inc><prob>\n",
    "    '''\n",
    "    queryFeatures = [split[1].split(':')[1]]\n",
    "\n",
    "    return queryFeatures\n",
    "\n",
    "def extractPairsOfRatedSites(y_train, Query):\n",
    "    '''\n",
    "    For each queryid, extract all pairs of documents\n",
    "    with different relevance judgement and save them in\n",
    "    a list with the most relevant in position 0\n",
    "    '''\n",
    "    pairs = []\n",
    "    for i in xrange(0, len(Query)):\n",
    "        for j in xrange(i+1, len(Query)):\n",
    "            #Only look at queries with the same id\n",
    "            if(Query[i] != Query[j]):\n",
    "                break\n",
    "            #Document pairs found with different rating\n",
    "            if(Query[i] == Query[j] and y_train[i] != y_train[j]):\n",
    "                #Sort by saving the largest index in position 0\n",
    "                if(y_train[i] > y_train[j]):\n",
    "                    pairs.append([i, j])\n",
    "                else:\n",
    "                    pairs.append([j, i])\n",
    "    print('Found %d document pairs' %(len(pairs)))\n",
    "    return pairs\n",
    "\n",
    "def separate_training(X,pairs):\n",
    "    data1=[]\n",
    "    data2=[]\n",
    "    for i in pairs:\n",
    "        data1.append(X[i[0]])\n",
    "        data2.append(X[i[1]])\n",
    "    return np.array(data1),np.array(data2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data from file...\n",
      "Read 723412 lines from file...\n",
      "Found 213868 document pairs\n"
     ]
    }
   ],
   "source": [
    "#Read training data\n",
    "X_train, y_train, Query = readDataset('./MSLR-WEB10K/Fold1/train.txt')\n",
    "\n",
    "# Taking first 500 queries:\n",
    "len_train=5000\n",
    "X_train1,y_train1=X_train[0:len_train],y_train[0:len_train]\n",
    "Query1=Query[0:len_train]\n",
    "\n",
    "# Extract document pairs\n",
    "#pairs1 = extractPairsOfRatedSites(y_train1, Query1)\n",
    "pairs1 = extractPairsOfRatedSites(y_train1, Query1)\n",
    "\n",
    "X_array=np.array(X_train1)\n",
    "data1,data2=separate_training(X_array,pairs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constant, variables and place holders:\n",
    "nDim=data1.shape[1]\n",
    "N=data1.shape[0]\n",
    "first_layer=10\n",
    "output_layer=1\n",
    "A = tf.placeholder(tf.float32, [None, nDim])\n",
    "B = tf.placeholder(tf.float32, [None, nDim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P_AB = tf.placeholder(tf.float32, [None, 1])\n",
    "P_true = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights for the first layer to hidden layer:\n",
    "weights1 = tf.Variable(tf.random_normal([nDim, first_layer]))\n",
    "biases1 = tf.Variable(tf.random_normal([first_layer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hidden Layer nodes:\n",
    "hiddenA = tf.matmul(A, weights1) + biases1\n",
    "hiddenB = tf.matmul(B, weights1) + biases1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Activations hidden layer\n",
    "act_hiddenA = tf.nn.sigmoid(hiddenA)\n",
    "act_hiddenB = tf.nn.sigmoid(hiddenB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights from hidden layer to output layer:\n",
    "weights2 = tf.Variable(tf.random_normal([first_layer,output_layer]))\n",
    "biases2 = tf.Variable(tf.random_normal([output_layer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output layer:\n",
    "outputA = tf.matmul(act_hiddenA, weights2) + biases2\n",
    "outputB = tf.matmul(act_hiddenB, weights2) + biases2\n",
    "\n",
    "Oi = tf.nn.sigmoid(outputA)\n",
    "Oj = tf.nn.sigmoid(outputB)\n",
    "Oij=Oi-Oj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Â Probability:\n",
    "Pij=tf.exp(Oij)/(1+tf.exp(Oij))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross entropy and cost:\n",
    "cross_entropy = -tf.reduce_sum(tf.log(Pij))\n",
    "#cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Pij,labels=P_true)\n",
    "#cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer:\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.00015).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start session:\n",
    "batch_size = 100\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P_target=np.ones([data1.shape[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "#        A_batch, y_true_batch = data.train.next_batch(batch_size)\n",
    "        indices = np.random.choice(data1.shape[0], batch_size)\n",
    "        A_batch, B_batch, target_batch = data1[indices], data2[indices] , P_target[indices]\n",
    "        \n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        # Note that the placeholder for y_true_cls is not set\n",
    "        # because it is not used during training.\n",
    "        #\n",
    "        #feed_dict_train = {A: data1,B:data2, P_true: target} --> working\n",
    "        feed_dict_train = {A: A_batch,B:B_batch, P_true: target_batch} \n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        #oi = session.run(Oi, feed_dict= feed_dict_train)\n",
    "        #oj = session.run(Oj, feed_dict= feed_dict_train)\n",
    "        #oij = session.run(Oij, feed_dict= feed_dict_train)\n",
    "        #pij = session.run(Pij, feed_dict= feed_dict_train)\n",
    "        c_e = session.run(cross_entropy, feed_dict= feed_dict_train)\n",
    "        #error = session.run(cost, feed_dict= feed_dict_train)\n",
    "        print('Epoch', i, \"pij \",c_e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'pij ', 71.417557)\n",
      "('Epoch', 1, 'pij ', 68.537781)\n",
      "('Epoch', 2, 'pij ', 71.048203)\n",
      "('Epoch', 3, 'pij ', 70.87294)\n",
      "('Epoch', 4, 'pij ', 71.197083)\n",
      "('Epoch', 5, 'pij ', 71.768738)\n",
      "('Epoch', 6, 'pij ', 67.665123)\n",
      "('Epoch', 7, 'pij ', 71.295334)\n",
      "('Epoch', 8, 'pij ', 70.438354)\n",
      "('Epoch', 9, 'pij ', 70.881599)\n",
      "('Epoch', 10, 'pij ', 68.809731)\n",
      "('Epoch', 11, 'pij ', 69.518784)\n",
      "('Epoch', 12, 'pij ', 69.393433)\n",
      "('Epoch', 13, 'pij ', 70.630615)\n",
      "('Epoch', 14, 'pij ', 68.610779)\n",
      "('Epoch', 15, 'pij ', 68.944077)\n",
      "('Epoch', 16, 'pij ', 69.500565)\n",
      "('Epoch', 17, 'pij ', 69.251251)\n",
      "('Epoch', 18, 'pij ', 68.300026)\n",
      "('Epoch', 19, 'pij ', 70.596436)\n",
      "('Epoch', 20, 'pij ', 72.004471)\n",
      "('Epoch', 21, 'pij ', 71.970871)\n",
      "('Epoch', 22, 'pij ', 70.522217)\n",
      "('Epoch', 23, 'pij ', 68.116547)\n",
      "('Epoch', 24, 'pij ', 71.126862)\n",
      "('Epoch', 25, 'pij ', 71.565155)\n",
      "('Epoch', 26, 'pij ', 68.773254)\n",
      "('Epoch', 27, 'pij ', 69.646286)\n",
      "('Epoch', 28, 'pij ', 70.025238)\n",
      "('Epoch', 29, 'pij ', 70.252258)\n",
      "('Epoch', 30, 'pij ', 68.615288)\n",
      "('Epoch', 31, 'pij ', 69.974457)\n",
      "('Epoch', 32, 'pij ', 69.434189)\n",
      "('Epoch', 33, 'pij ', 69.615219)\n",
      "('Epoch', 34, 'pij ', 69.445335)\n",
      "('Epoch', 35, 'pij ', 69.085167)\n",
      "('Epoch', 36, 'pij ', 70.298828)\n",
      "('Epoch', 37, 'pij ', 70.970215)\n",
      "('Epoch', 38, 'pij ', 69.427383)\n",
      "('Epoch', 39, 'pij ', 70.274384)\n",
      "('Epoch', 40, 'pij ', 70.3685)\n",
      "('Epoch', 41, 'pij ', 68.547653)\n",
      "('Epoch', 42, 'pij ', 68.14006)\n",
      "('Epoch', 43, 'pij ', 70.811203)\n",
      "('Epoch', 44, 'pij ', 69.170883)\n",
      "('Epoch', 45, 'pij ', 69.544952)\n",
      "('Epoch', 46, 'pij ', 69.12764)\n",
      "('Epoch', 47, 'pij ', 69.933762)\n",
      "('Epoch', 48, 'pij ', 69.689735)\n",
      "('Epoch', 49, 'pij ', 69.787476)\n",
      "('Epoch', 50, 'pij ', 69.689713)\n",
      "('Epoch', 51, 'pij ', 69.677139)\n",
      "('Epoch', 52, 'pij ', 69.88147)\n",
      "('Epoch', 53, 'pij ', 69.446281)\n",
      "('Epoch', 54, 'pij ', 70.523743)\n",
      "('Epoch', 55, 'pij ', 68.896477)\n",
      "('Epoch', 56, 'pij ', 70.143539)\n",
      "('Epoch', 57, 'pij ', 68.598572)\n",
      "('Epoch', 58, 'pij ', 71.257065)\n",
      "('Epoch', 59, 'pij ', 71.114044)\n",
      "('Epoch', 60, 'pij ', 69.377457)\n",
      "('Epoch', 61, 'pij ', 70.975929)\n",
      "('Epoch', 62, 'pij ', 70.810913)\n",
      "('Epoch', 63, 'pij ', 70.693916)\n",
      "('Epoch', 64, 'pij ', 70.490417)\n",
      "('Epoch', 65, 'pij ', 69.793839)\n",
      "('Epoch', 66, 'pij ', 69.150162)\n",
      "('Epoch', 67, 'pij ', 69.17205)\n",
      "('Epoch', 68, 'pij ', 69.989922)\n",
      "('Epoch', 69, 'pij ', 69.160324)\n",
      "('Epoch', 70, 'pij ', 68.26059)\n",
      "('Epoch', 71, 'pij ', 70.190079)\n",
      "('Epoch', 72, 'pij ', 70.893852)\n",
      "('Epoch', 73, 'pij ', 68.417648)\n",
      "('Epoch', 74, 'pij ', 68.58432)\n",
      "('Epoch', 75, 'pij ', 71.137558)\n",
      "('Epoch', 76, 'pij ', 71.741409)\n",
      "('Epoch', 77, 'pij ', 70.59005)\n",
      "('Epoch', 78, 'pij ', 70.600594)\n",
      "('Epoch', 79, 'pij ', 68.932983)\n",
      "('Epoch', 80, 'pij ', 69.741898)\n",
      "('Epoch', 81, 'pij ', 70.64254)\n",
      "('Epoch', 82, 'pij ', 68.545265)\n",
      "('Epoch', 83, 'pij ', 69.520615)\n",
      "('Epoch', 84, 'pij ', 70.998383)\n",
      "('Epoch', 85, 'pij ', 70.630585)\n",
      "('Epoch', 86, 'pij ', 70.242439)\n",
      "('Epoch', 87, 'pij ', 70.381287)\n",
      "('Epoch', 88, 'pij ', 70.160919)\n",
      "('Epoch', 89, 'pij ', 70.825989)\n",
      "('Epoch', 90, 'pij ', 69.03965)\n",
      "('Epoch', 91, 'pij ', 68.715744)\n",
      "('Epoch', 92, 'pij ', 68.78521)\n",
      "('Epoch', 93, 'pij ', 69.591675)\n",
      "('Epoch', 94, 'pij ', 69.404724)\n",
      "('Epoch', 95, 'pij ', 69.086327)\n",
      "('Epoch', 96, 'pij ', 69.891182)\n",
      "('Epoch', 97, 'pij ', 69.308701)\n",
      "('Epoch', 98, 'pij ', 69.575768)\n",
      "('Epoch', 99, 'pij ', 70.434036)\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = tf.round(Pij * 2) / 2\n",
    "prediction= tf.cast(prediction, tf.float64)\n",
    "correct_prediction = tf.equal(P_target, prediction)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data from file...\n",
      "Read 235259 lines from file...\n",
      "Found 10103042 document pairs\n"
     ]
    }
   ],
   "source": [
    "#Read training data\n",
    "X_val, y_val, Query_val = readDataset('./MSLR-WEB10K/Fold1/vali.txt')\n",
    "\n",
    "# Extract document pairs\n",
    "pairs_val = extractPairsOfRatedSites(y_val, Query_val)\n",
    "X_val_array=np.array(X_val)\n",
    "data1_val,data2_val=separate_training(X_val_array,pairs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_target_val=np.ones([data1_val.shape[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_test=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict_test = {A: data1_val[0:len_test],B:data2_val[0:len_test] ,P_true: P_target_val[0:len_test]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [213868,1] vs. [500,1]\n\t [[Node: Equal_3 = Equal[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal_3/x, Cast_4)]]\n\nCaused by op u'Equal_3', defined at:\n  File \"/Users/Chelo/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-d8b2fc43ff77>\", line 3, in <module>\n    correct_prediction = tf.equal(P_target, prediction)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in equal\n    result = _op_def_lib.apply_op(\"Equal\", x=x, y=y, name=name)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [213868,1] vs. [500,1]\n\t [[Node: Equal_3 = Equal[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal_3/x, Cast_4)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-6789fcd6b14d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-8e66dc27a46a>\u001b[0m in \u001b[0;36mprint_accuracy\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Use TensorFlow to compute the accuracy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Print the accuracy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [213868,1] vs. [500,1]\n\t [[Node: Equal_3 = Equal[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal_3/x, Cast_4)]]\n\nCaused by op u'Equal_3', defined at:\n  File \"/Users/Chelo/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-d8b2fc43ff77>\", line 3, in <module>\n    correct_prediction = tf.equal(P_target, prediction)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in equal\n    result = _op_def_lib.apply_op(\"Equal\", x=x, y=y, name=name)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Chelo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [213868,1] vs. [500,1]\n\t [[Node: Equal_3 = Equal[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal_3/x, Cast_4)]]\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
