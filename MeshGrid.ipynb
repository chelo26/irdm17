{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "#Parameters for models\n",
    "#Change them round here\n",
    "#[ -round <T> ]\tThe number of rounds to train (default=300)\n",
    "#[ -tc <k> ]\tNumber of threshold candidates to search. -1 to use all feature values (default=10)\n",
    "#pick some small parameters first to make sure it is working\n",
    "\n",
    "parameters={'-round':[ 100, 200,  300, 400, 500, 1000, 1500], '-tc': [5, 10, 15, 30, 50]}\n",
    "\n",
    "#train model(s)\n",
    "for round_ in parameters['-round']:\n",
    "    for tc in parameters['-tc']:\n",
    "        #train code\n",
    "        print('train_code', 'round', round_,'tc',  tc)\n",
    "        train_code = 'java -jar RankLib.jar -train MSLR-WEB10K/Fold1/train.txt -validate MSLR-WEB10K/Fold1/vali.txt -ranker 2 -norm zscore  -save RB_models/RB_model_r%s_tc%s.txt -round %s -tc %s' %(round_, tc, round_, tc)          \n",
    "        subprocess.run(train_code.split())\n",
    "\n",
    "def get_list_models(directory_name):\n",
    "    list_models=[]\n",
    "    for file in os.listdir(directory_name):\n",
    "        if file.endswith(\".txt\"):\n",
    "            list_models.append(os.path.join(directory_name, file))\n",
    "    return list_models\n",
    "\n",
    "models=get_list_models('RB_models/')\n",
    "\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -rank MSLR-WEB10K/Fold1/test.txt -score test_RB_rank_score_%s'%(model, model[10:])\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "\n",
    "ERR={}\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -test MSLR-WEB10K/Fold1/test.txt -metric2T ERR@10 '%(model)\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "    string_ouput=str(output)\n",
    "    ERR['%s' %(model[10:])]=eval(string_ouput[-9:-3])\n",
    "    \n",
    "NDCG={}\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -test MSLR-WEB10K/Fold1/test.txt -metric2T ERR@10 '%(model)\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "    string_ouput=str(output)\n",
    "    NDCG['%s' %(model[10:])]=eval(string_ouput[-9:-3])\n",
    "    \n",
    "\n",
    "#dictionary containing the model name and the NDCG value\n",
    "ERR\n",
    "\n",
    "ERR\n",
    "#RB_model_r100_tc10.txt NDCG 0.3581\n",
    "#RB_model_r100_tc10.txt ERR 0.2518\n",
    "#RN_model_e20_l2_n1_lr5e-05.txt NDCG 0.215\n",
    "#RN_model_e20_l2_n1_lr5e-05.txt ERR 0.1491\n",
    "#LambdaMART1.txt NDCG 0.4452\n",
    "#LambdaMART1.txt ERR 0.3449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Parameters for models\n",
    "#Default paramers:\n",
    "#[ -tree <t> ]\tNumber of trees (default=1000)\n",
    "#[ -leaf <l> ]\tNumber of leaves for each tree (default=10)\n",
    "#[ -shrinkage <factor> ]\tShrinkage, or learning rate (default=0.1)\n",
    "#[ -tc <k> ]\tNumber of threshold candidates for tree spliting. -1 to use all feature values (default=256)\n",
    "#[ -mls <n> ]\tMin leaf support -- minimum #samples each leaf has to contain (default=1)\n",
    "#[ -estop <e> ]\tStop early when no improvement is observed on validaton data in e consecutive rounds (default=100)\n",
    "\n",
    "#to test it is working put in some small values for all of these before running anything too big\n",
    "parameters={'-tree':[500, 850, 1000, 1250, 1500], '-leaf': [1,5, 10], '-shrinkage':[0.01], '-tc':[ 256], '-estop':[1]}\n",
    "\n",
    "#Saves trained model(s)\n",
    "for tree in parameters['-tree']:\n",
    "    for leaf in parameters['-leaf']:\n",
    "        for tc in parameters['-tc']:\n",
    "            for estop in parameters['-estop']:\n",
    "                #train code\n",
    "                if os.path.isfile('LM_models/LM_model_t%s_l%s_tc%s_stop%s.txt'%(tree, leaf, tc, estop)):\n",
    "                    print('LM_models/LM_model_t%s_l%s_tc%s_stop%s.txt'%(tree, leaf, tc, estop))\n",
    "                    print('already run')\n",
    "                else:\n",
    "                    print('running model','tree', tree,'leaf',  leaf, 'tc', tc,'estop', estop)\n",
    "                    train_code = 'java -jar RankLib.jar -train MSLR-WEB10K/Fold1/train.txt -validate MSLR-WEB10K/Fold1/vali.txt -ranker 6 -norm zscore -metric2t NDCG@10  -save LM_models/LM_model_t%s_l%s_tc%s_stop%s.txt -tree %s -leaf %s -tc %s -estop %s' %(tree, leaf, tc, estop, tree, leaf, tc, estop)          \n",
    "                    subprocess.run(train_code.split())\n",
    "\n",
    "models=get_list_models('LM_models/')\n",
    "\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -rank MSLR-WEB10K/Fold1/test.txt -score test_RB_rank_score_%s'%(model, model[10:])\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "\n",
    "ERR={}\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -test MSLR-WEB10K/Fold1/test.txt -metric2T ERR@10 '%(model)\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "    string_ouput=str(output)\n",
    "    ERR['%s' %(model[10:])]=eval(string_ouput[-9:-3])\n",
    "    \n",
    "NDCG={}\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -test MSLR-WEB10K/Fold1/test.txt -metric2T ERR@10 '%(model)\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "    string_ouput=str(output)\n",
    "    NDCG['%s' %(model[10:])]=eval(string_ouput[-9:-3])\n",
    "    \n",
    "#tests model(s) against NDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for models\n",
    "\n",
    "#[ -epoch <T> ]\tThe number of epochs to train (default=100)\n",
    "#[ -layer <layer> ]\tThe number of hidden layers (default=1)\n",
    "#[ -node <node> ]\tThe number of hidden nodes per layer (default=10)\n",
    "#[ -lr <rate> ]\tLearning rate (default=0.00005)\n",
    "\n",
    "#to test it is working put in some small values for all of these before running anything too big\n",
    "parameters={'-epoch':[ 50, 100, 150, 200], '-layer':[1, 2,3,4,5], '-node':[5,10,15,20, 30], '-lr':[0.005, 0.00005]}\n",
    "\n",
    "#trains model and saves it with the model name containing the parameter values\n",
    "import pickle\n",
    "for epoch in parameters['-epoch']:\n",
    "    for layer in parameters['-layer']:\n",
    "        for node in parameters['-node']:\n",
    "            for learning_rate in parameters['-lr']:\n",
    "                #train code\n",
    "                if os.path.isfile('RN_models/RN_model_test_e%s_l%s_n%s_lr%s.txt'%(epoch, layer, node, learning_rate)):\n",
    "                    print('RN_models/RN_model_test_e%s_l%s_n%s_lr%s.txt'%(epoch, layer, node, learning_rate))\n",
    "                    print('already run')\n",
    "                else:\n",
    "                    print('train_code', 'epoch', epoch, 'layer', layer, 'node', node, 'learning_rate', learning_rate)\n",
    "                    train_code = 'java -jar RankLib.jar -train MSLR-WEB10K/Fold1/train.txt -test MSLR-WEB10K/Fold1/test.txt -validate MSLR-WEB10K/Fold1/vali.txt -ranker 1 -norm zscore  -save RN_models/RN_model_test_e%s_l%s_n%s_lr%s.txt -epoch %s -layer %s -node %s -lr %s' %(epoch, layer, node, learning_rate, epoch, layer, node, learning_rate)          \n",
    "                    subprocess.run(train_code.split())\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "#test code against NDCG criteris\n",
    "models=get_list_models('RN_models/')\n",
    "\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -rank MSLR-WEB10K/Fold1/test.txt -score test_RB_rank_score_%s'%(model, model[10:])\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "\n",
    "ERR={}\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -test MSLR-WEB10K/Fold1/test.txt -metric2T ERR@10 '%(model)\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "    string_ouput=str(output)\n",
    "    ERR['%s' %(model[10:])]=eval(string_ouput[-9:-3])\n",
    "    \n",
    "NDCG={}\n",
    "for model in models:\n",
    "    test_code='java -jar RankLib.jar -load %s -test MSLR-WEB10K/Fold1/test.txt -metric2T ERR@10 '%(model)\n",
    "    output = subprocess.check_output(test_code.split())\n",
    "    string_ouput=str(output)\n",
    "    NDCG['%s' %(model[10:])]=eval(string_ouput[-9:-3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
